[{"title":"Day218","date":"","description":"","body":"WFH Day 218 Today was the day! Adobe MAX arrived, and all the work of the previous months could be seen by everybody interested in our products. What a fantastic achievement in these crazy times.\nI\u0026rsquo;m still fighting with a couple of things.\n my 3D Printer drives me crazy (filament clogged the extruder, and I didn\u0026rsquo;t have the Teflon tube I needed to replace) working on some authentication-related issues for the CSDK, and it moves slow and brought up some obstacles along the way that makes the implementation more expensive. I think that I found a solution that I need to finalize  Otherwise, I\u0026rsquo;m looking forward to my trip to Germany this Saturday. Not that Germany is the best place to travel right now, but I want to be there for my little daughter\u0026rsquo;s birthday. And that\u0026rsquo;s important to me.\nA good friend shared this lovely video a couple of days ago. I like the way it\u0026rsquo;s animated and narrated.\nhttps://www.nfb.ca/film/how-to-be-at-home/\n How To Be At Home, Andrea Dorfman, provided by the National Film Board of Canada\n","ref":"/cv19wfh/2020/day218/"},{"title":"Day205","date":"","description":"","body":"WFH Day 205 I\u0026rsquo;m currently working on some very tricky programming issues at work. Things are moving slowly, and there are times when I think what the hell am I doing here. Luckily, this is a temporary state and will only get worse by working on something entirely different. Right, working on the leetcode October challenge can show me that things can get worse. Last night I spent 3 hours! On a simple (in retrospect, it was a straightforward) problem. Inserting something into a BST and return the resulting BST. Perhaps it was too late, I didn\u0026rsquo;t pay enough attention to the little details along the way, but I got something working on my machine, and when I pasted it into the leetcode editor, it wasn\u0026rsquo;t working anymore. Great! WHY IS THIS NOT WORKING?! I got it working locally, and now this. Sigh. I didn\u0026rsquo;t get the points for that day, and I went to bed slightly frustrated about the outcome. Anyway, it should be fun and entertaining, but it wasn\u0026rsquo;t.\nEarly this morning, I looked at the problem again and tried several things to debug the issue to make it work in leetcode. And then I finally found the stupid mistake I made. So, I could fix it and throw away 60% of my solution, since the code I wrote to turn an array with numbers into a BST was unnecessary at all. Since the input from the test case looked like an array, I built some function to create a BST from that serialized BST and then insert the new number into the BST. But the test case input was already an instance of the BST, and I just needed to binary search that tree and insert the value at the correct spot.\nLesson learned:\n read the instructions carefully inspect the input data from the test cases don\u0026rsquo;t do it late at night  And perhaps use a different language with a better type system (I was initially using javascript). Looking at the TypeScript scaffold for the solution made it clear to me that the input to the function is an instance of the class defined in the comment. The function parameter didn\u0026rsquo;t show the type in the javascript version, and I skipped the function comment. So, an obvious User error.\nAnyway, I solved the problem today much more comfortable by being more careful. And the Oakland Athletics won the 3rd game of the postseason beating the sh** out of the Astros. Go A\u0026rsquo;s!!!\nBTW: If you want to know how it feels about interviewing for a software engineering position at some high profile companies, I recommend watching this analogy for when the same principles apply for doctors.\nIf Doctors were interviewed like software engineers\nMahalo üå∏\n","ref":"/cv19wfh/2020/day205/"},{"title":"Day200","date":"","description":"","body":"WFH Day 200 Time to celebrate üéÜ\n200 days WFH and mostly isolated and not entirely insane ;-)\nWho would have guessed that it will last that long? And there is no end in sight\nLet\u0026rsquo;s look at something tiny through a Macro Lens. Should we? Just to distract ourselves\nShot on Canon 6D with a 90mm Tamron Macro Lens\n  Red and Small      ","ref":"/cv19wfh/2020/day200/"},{"title":"Day197","date":"","description":"","body":"WFH Day 197 We are getting close to the 200-day mark for work at home. Not necessarily something to celebrate, but a noticeable milestone during these times and a sign that every prediction how long this situation is supposed to last was wrong. Only a couple of weeks left before the election, and tonight is the first debate between both presidential candidates. To protect my sanity, I\u0026rsquo;ll watch the debate only for 15 mins max. That debate will be a battle that I can\u0026rsquo;t stand.\nOne Highlight these days: The Oakland Athletics made it to the Playoffs! That is great, and I hope that after the rocky start today, that they will be more successful tomorrow in game #2.\n","ref":"/cv19wfh/2020/day197/"},{"title":"Day192","date":"","description":"","body":"WFH Day 192 We are approaching the final days of our Sprint. The majority of our clients are happy and don\u0026rsquo;t have significant functionality issues that would require our team to do some fire fighting. I was able to finish one last-minute task for a hotfix and another task for this release. In addition to finalizing both tasks, I was able to review some PRs and provide some feedback. I feel pretty accomplished today, and I\u0026rsquo;m looking forward to tomorrow. Last workday of this week üå∏\nThe picture shows what I\u0026rsquo;m sometimes doing for my afternoon break after I finished some work. Brewing coffee the old fashioned way. Beans, Grinder, Paper filter, Chemex, and hot water. And don\u0026rsquo;t forget the scale and the timer. This ritual shifts the focus towards the coffee smell and the great taste of a freshly made coffee.\n  Chemex. Not Chemical     Date: September 22, 2020 Aperture: 2.00 Brightness: 0.94 Exposure Time: 1/40 F Number: 2 Focal Length: 6 ISO Speed Ratings: 400 Lens Model: iPhone 11 Pro Max back dual camera 6mm f/2  ","ref":"/cv19wfh/2020/day192/"},{"title":"Day189","date":"","description":"","body":"WFH Day 189 Today was a \u0026ldquo;Terrible, Horrible, No Good, Very Bad Day\u0026rdquo;. I tried to make the best out of it. No luck. I woke up feeling like a truck rolled over my body. I pushed through the day and went for a run in the evening. Tomorrow is a new day. Looking forward to a fresh start.\n  Choose One     Date: July 17, 2019 Aperture: 1.70 Brightness: 5.64 Exposure Time: 1/180 F Number: 1.8 Focal Length: 4.25 ISO Speed Ratings: 25 Lens Model: iPhone XS Max back camera 4.25mm f/1.8  ","ref":"/cv19wfh/2020/day189/"},{"title":"Day186","date":"","description":"","body":"WFH Day 186 Today was a great day! You may ask why it was a great day. Let me tell you that my employer is giving us a day off. On Fridays. Every three weeks. Until the end of the year! If this is not great, I don\u0026rsquo;t know how to spark some fun. At least for the moment. I don\u0026rsquo;t know when it was the last time that I needed an additional day to recover. I love my job. For sure, it has its ups and downs. But in general, I love what I do. But I feel tired recently, and everything seems to need a lot of energy to move it forward. I don\u0026rsquo;t know if it\u0026rsquo;s only me or a sign of the circumstances we currently live through. I\u0026rsquo;m thankful to have a job and contribute to something that means something to me. But it doesn\u0026rsquo;t always spark joy.\nI used part of the day to go outside and ride my bicycle for nearly 3 hours over 35 miles and almost 2500 ft elevation. I enjoyed nature, the quietness, and the sun on my body. It was challenging since I didn\u0026rsquo;t work out enough in the past couple of months. But I climbed up the mountains and was happy that I made it to the top. The view was excellent, the air quality was great, and I felt a sense of accomplishment that I could push myself up against that mountain. I felt like a winner. Excellent after months of pushing through work items, meetings, the pandemic, my family living distributed in different countries. I was so tired and my legs cramped when I arrived back at home. Nonetheless, I felt alive, although my muscles being sore, and my body aching. But better this way than dead.\nHere is a picture from the top of the mountain that I climbed.   Top of the mountain     Date: September 18, 2020 Aperture: 2.00 Brightness: 10.37 Exposure Time: 1/1800 F Number: 2 Focal Length: 6 ISO Speed Ratings: 20 Lens Model: iPhone 11 Pro Max back camera 6mm f/2  ","ref":"/cv19wfh/2020/day186/"},{"title":"Day184","date":"","description":"","body":"WFH Day 184 What a day. A lot of meetings in the morning. After I finished all of them right before the lunch break, I found Beat Burnout And Zoom Fatigue: 3 Ways To Fight Stress And Stay Motivated During Coronavirus in my news feed today. Although I consider myself mindful and remind myself to take breaks during the day, exercise my aching body, I still sometimes feel tired and not motivated to my full extent. I don\u0026rsquo;t know if it\u0026rsquo;s a result of all the meetings to stay connected with my teammates and friends and family. But I can feel the pressure that is building up. The pace is high, and the work seems to be endless. It\u0026rsquo;s unlikely that I\u0026rsquo;m running out of tasks, but I need to be more disciplined about stopping on time and not going back to work after dinner. I will do better tomorrow.\nI\u0026rsquo;m happy that I was able to do some core exercises for 20 minutes. It was giving me a different form of challenge, and it was tiring. I should sleep well tonight. And I hope that I\u0026rsquo;ll be able to lift my arms tomorrow morning.\nAnd now something for the eyes. I believe that looking at something green should be relaxing to the eyes. ;-)   Macroshot of Dandelion     Date: July 13, 2020 Aperture: 1.70 Brightness: 5.01 Exposure Time: 1/120 F Number: 1.8 Focal Length: 4.25 ISO Speed Ratings: 50 Lens Model: iPhone 11 Pro Max back camera 4.25mm f/1.8  ","ref":"/cv19wfh/2020/day184/"},{"title":"Day183","date":"","description":"","body":"WFH Day 183 How many T-shirts do I need? I did laundry today and was folding up my stuff. I was looking in my closet and found at least 20 T-Shirts and the additional pile of 15 T-shirts freshly laundered. I need to get rid of some of them. There is so much stuff in my life that it distracts me from more important things. I have this pile of desk supplies lying on the ground next to my desk. I have a todo item on my list to put them into the drawer or throw them away. I think tomorrow will be a fine day to start doing that.\nThe air quality was much better than the last couple of days. Time to go on my evening walk through the neighborhood again.\nAnd now something for sore eyes.\n  Flower on the Wall     Date: August 16, 2020 Aperture: 1.70 Brightness: 5.65 Exposure Time: 1/100 F Number: 1.8 Focal Length: 4.25 ISO Speed Ratings: 32 Lens Model: iPhone 11 Pro Max back camera 4.25mm f/1.8  ","ref":"/cv19wfh/2020/day183/"},{"title":"Day182","date":"","description":"","body":"WFH Day 182 That is a looong time that we are now hanging out at home. We won\u0026rsquo;t go back to the office anytime soon. So, we are stuck inside our homes for much longer. And because of the horrible air quality I can\u0026rsquo;t even go outside and exercise. It seems that this year brings all the catastrophes (pandemic, global warming, extreme heat and wildfires) in one go. This is usual material that science fictions stories are made of. Now we have to live through it in reality. We will all be alright. Some way or the other. No time to worry about it.\nLet\u0026rsquo;s add a picture to have something nicer to look at.\n  Pink Flower     Date: August 28, 2020 Aperture: 1.70 Brightness: 5.22 Exposure Time: 1/122 F Number: 1.8 Focal Length: 4.25 ISO Speed Ratings: 50 Lens Model: iPhone 11 Pro Max back camera 4.25mm f/1.8  ","ref":"/cv19wfh/2020/day182/"},{"title":"Day178","date":"","description":"","body":"WFH Day 178 In addition to work from home we got really bad air quality. We didn\u0026rsquo;t see the sun since yesterdays orange tint. Today was not as bad as yesterday, but still no sun and it was gloomy as hell. This doesn\u0026rsquo;t give you any energy boost to get through the day. And don\u0026rsquo;t think about outside exercise. Trying to do something healthy gets in the way with the outside conditions.\n","ref":"/cv19wfh/2020/day178/"},{"title":"Day26","date":"","description":"","body":"WFH Day #26 Photo by Viktor Nikolaienko on Unsplash unsplash-logoViktor Nikolaienko","ref":"/cv19wfh/2020/day26/"},{"title":"Design for Coffee Ground Distribution Tool Base with OpenSCAD","date":"","description":"Use OpenSCAD to design a Base to hold a Coffee ground distribution tool","body":"TL;DR A friend of mine asked me if I could build something useful with my 3D Printer. He wanted to have something to place his new (and expensive) tamper for ground coffee. I always wanted to design and print something useful on my 3D Printer. And I wanted to learn and use OpenSCAD for a long time. Now I had an excellent reason to learn it.\nCreate the Design  I had no experience with OpenSCAD at all when I started this little project. OpenSCAD comes with a lot of examples and a short Cheat Sheet that is extremely helpful in learning OpenSCAD.\n OpenSCAD uses a simple programming language to describe geometric shapes. These shapes can be modified by having functions to create them with variable parameters. That makes it easy to modify a design by changing a parameter, and everything that depends on that parameter will adjust accordingly. This parametric design principle is partly used by some professional-grade CAD programs (Fusion360, AutoCAD). It\u0026rsquo;s not a new thing. OpenSCAD has a much lower bar, IMHO, to create a parametric design.\nDesign Considerations I wanted to keep it simple for the first project. I envisioned a square that is big enough to hold the tool, a circle/cylinder on top of that square, to fit around the circular metal base of the tool tightly. The bottom should not be too big since it will be used in an environment with limited surface space. But it should not be too small to avoid falling over. So far, this sounds doable.\nThe challenges I encountered along the way\n How do I create a hollow cylinder with a specific wall width? How can I create rounded corners for the square base? How can I add some text on top of the base (give it a personal note)? How can I add some text embossed on the side of the Base (copyright text)?  Let\u0026rsquo;s look at the implementation.\nCreating the Square Base module RoundedCornerSquareBase() { minkowski() { // the square base  translate([0, 0, baseHeight / 2]) { color(\u0026#34;blue\u0026#34;) cube([baseWidth, baseLength, baseHeight], center=true); } // create rounded corners  cylinder(r=5, h=1); } } Create a module (like a function) and create the base square with cube and center it around all the axes. Use translate to move the square up the z-axis, so that the bottom of the square is not in the negative x and y coordinate space.\nThe tricky part for me was to figure out how to have rounded corners for the square. OpenSCAD provides the transformation function minkowski that will sum up multiple shapes into one shape. More details are available here. minkowski takes the cube and the cylinder from the code above and sums them up into a square with rounded corners. This sum increases the width and height of the square by the radius of the cylinder.\n  Square Base rendered in OpenSCAD   Add the Hollow Cylinder module HollowCylinder() { translate([0, 0, baseHeight]) { difference() { cylinder(h=maxHeight, d=diameter + wallThickness); cylinder(h=maxHeight, d=diameter); } }; } The solution was not too difficult after I found the difference function. Take two cylinders with different diameters and place them in the same position and let the difference function figure it out.\n  Hollow Cylinder rendered in OpenSCAD   Add the Text on top of the Base module CoffeeShopName() { // place coffee shop name on top of base  translate([0, -39, baseHeight + 1]) { linear_extrude(0.5) { text(coffeeShopName, font=\u0026#34;Gill Sans:style=Bold\u0026#34;, size=9, halign=\u0026#34;center\u0026#34;); } } } Placing the text was a bit of trial and error to find the correct position on top of the base square. Then I encountered the issue that the text height wasn\u0026rsquo;t enough to stick out a bit from the surface. After inspecting examples and searching the internet, I found that linear_extrude function that can be used to make something flat grow in height.\n  Top Text rendered in OpenSCAD   Add the debossed Text on the side of the Base module RoundedCornerSquareBase() { minkowski() { // the square base  translate([0, 0, baseHeight / 2]) { color(\u0026#34;blue\u0026#34;) cube([baseWidth, baseLength, baseHeight], center=true); } // create rounded corners  cylinder(r=5, h=1); } } module CopyrightNotice() { mirror([0, 180, 0]) { rotate([90, 0, 180]) { translate([0, 3, -44]) { linear_extrude(2) { text(copyrightName, size=6, halign=\u0026#34;center\u0026#34;); } } } } } difference() { RoundedCornerSquareBase(); CopyrightNotice(); } This text placed on the side of the square base took the most time for me to implement. I had come up with this solution that combines mirror, rotate, translate, and linear_extrude to create a simple text on the side of the base. I didn\u0026rsquo;t want this text to sit on top of the surface. So, I had to trial and error my way to find the correct placement. Once I had the correct position, I used the difference function to get the text debossed into the square base. It was worth it in the end, and I was happy with the result.\n  Debossed Text rendered in OpenSCAD   The Result The combination of all the code snippets looks like this.\n  Coffee Distribution Tool Base rendering in OpenSCAD   OpenSCAD Project Files The project Files are located in my github repository\nPrint Settings I printed the base on my Prusa i3 MKS2 with MMU2 with PETG Filament from Atomic Filament. I used PrusaSlicer 2.2.1 to slice the model with 20% Infill and no support on the smooth metal sheet.\nSummary It was fun to learn a different way to create 3D models. It takes some time to do certain things, like the copyright text. OpenSCAD is a powerful tool to program your 3D models. There are a lot of great examples that come with OpenSCAD, and I recommend inspecting them to learn how to realize specific effects. Since you have a programming language with control structures, loops, and functions, there are endless possibilities to create compelling models that would be otherwise difficult to realize (look at module_recursion.scad).\n If you find it useful or if you have questions, leave a comment and share this post. If you have any feedback for the design, clone the repo, then file an issue or submit a pull request.\nMahalo üå∏\n","ref":"/post/2020/design-a-coffee-ground-distribution-base/"},{"title":"Day1","date":"","description":"","body":"WFH Day 001 Today we got the notification from Adobe that we will close all the offices for all employees in north America. we were told to work from home for the next 30 days. After that period the situation will be evaluated and further decisions will be communicated by then. Let\u0026rsquo;s see what is going to happen.\n","ref":"/cv19wfh/2020/day1/"},{"title":"Learning Crystal With Genetic Algorithms","date":"","description":"Learning Crystal lang by re-implementing book samples originally written in Java","body":"I like to learn new tools, programming languages, and exciting topics. I recently found the book Genetic Algorithms in Java Basics , and I found the code samples easy enough to understand to \u0026ldquo;translate\u0026rdquo; them to a different programming language for the sole purpose of getting some hands-on experience with a new programming language. I\u0026rsquo;m done with the 2nd chapter of the book and implemented the genetic algorithm described in that chapter to crystal lang.\nThe source code is available from my github repo.\nIf you find it useful clone it and if you have feedback, then file an issue or submit a pull request.\nMahalo üå∏\n","ref":"/post/learning-crystal-with-genetic-algorithms/"},{"title":"Testing raw DOM Event Handler in Reactjs","date":"","description":"","body":"This is a reminder to myself. And to anybody who needs a creative solution to test an event handler directly attached to a DOM node of a react component.\nLast Friday I ran into the situation to test my react component to ensure that the state updates correctly when the pointerenter and pointerleave event fires. Testing for these events is usually no big deal when you use reactjs in one way or the other (either web or native). At work we use an internal framework that is react API compatible and implements most of the features of react. Most of them, but not all.\nI ran into the situation where I have the pointerenter event handler defined, but they didn\u0026rsquo;t fire. The team recommended to replace it with an event handler directly attached to the DOM node by\n assign a ref to the component attach the event handler to the ref  This is how it looked like class ImageHover extends React.Component { constructor(props) { super(props); this._hoverBoxRef = React.CreateRef(); } function _toggleHoverState = (state) =\u0026gt; { this.setState({ isNormal: state }); function componentDidMount() { this._hoverBoxRef.current.addEventListener(\u0026#39;pointerenter\u0026#39;, () =\u0026gt; this._toggleHoverState(false)); this._hoverBoxRef.current.addEventListener(\u0026#39;pointerleave\u0026#39;, () =\u0026gt; this._toggleHoverState(true)); } function componentWillUnmount() { this._hoverBoxRef.current.removeEventListener(\u0026#39;pointerenter\u0026#39;, () =\u0026gt; this._toggleHoverState(false)); this._hoverBoxRef.current.removeEventListener(\u0026#39;pointerleave\u0026#39;, () =\u0026gt; this._toggleHoverState(true)); } render () { style = this.state.isNormal ? \u0026#34;normal\u0026#34; : \u0026#34;hover\u0026#34;; return ( \u0026lt;div className={ style } onClick={this.props.onClick} ref={this._hoverBoxRef} /\u0026gt; ); }\nTo ensure that the component changes the style to hover when the pointerenter event fires and back to normal when pointerleave is fired can usually achieved by using the rendered component and call .simulate(\u0026quot;pointerEnter\u0026quot;) when using jest and enzyme.\nNormal test\ncb = jest.fn(); imageHover = mount(\u0026lt;ImageHover imageName={\u0026#34;phone\u0026#34;} onClick={cb} /\u0026gt;); it(\u0026#34;should change state on pointerEnter\u0026#34;, () =\u0026gt; { imageHover.simulate(\u0026#34;pointerEnter\u0026#34;); expect(imageHover.state().isNormal).toEqual(false); }); Since the pointerEnter event didn\u0026rsquo;t fire in my situation, I had to find another way to trigger that event. Here is the modified test\ncb = jest.fn(); imageHover = mount(\u0026lt;ImageHover imageName={\u0026#34;phone\u0026#34;} onClick={cb} /\u0026gt;); it(\u0026#34;should change state on pointerEnter\u0026#34;, () =\u0026gt; { const domNode = imageHover.getDOMNode(); const event = new Event(\u0026#34;pointerenter\u0026#34;); domNode.dispatchEvent(event); expect(imageHover.state().isNormal).toEqual(false); }); The tiny difference is getting access to the underlying DOM element during the test execution and dispatch the pointerenter event on that DOM node. I\u0026rsquo;ve omitted the event details in this example since they aren\u0026rsquo;t relevant for the demo purpose. Perhaps there is an alternative solution to achieve the same result without the direct DOM access. Let me know, and I\u0026rsquo;m happy to update my test code.\nThank you very much for reading!\n","ref":"/post/testing-dom-event-handler-in-reactjs/"},{"title":"ReactJS San Francisco Meetup at Zendesk","date":"","description":"Some notes from the recent SF ReactJS Meetup","body":"ReactJS San Francisco Meetup at Zendesk Thursday night I attended the SF ReactJS Meetup at Zendesk.\nFirst of all, there were some noticeable difference to some other meetups I went to in the past,\n No need to sign No need to sign an NDA before entering the premise No Pizza!  The office space is gorgeous. Grass on the wall, stairs to sit on and a small atrium like opening from the basement to the first floor to bring some light to the lower level.\nAnd as I mentioned, the food was IMHO delicious. Some Mediterranean style food from Birite. Delicious and welcome variation.\nSchedule and Speaker There was a gentle introduction from a representative of the HR department of Zendesk who welcomed the crowd and told them they are looking for engineers to join their team.\nThe speakers for that night\n Austin Green and Alan Hogan from Zendesk - Flexible and Accessible Component Design in the Zendesk - Design System Slides Jon Wong from Coursera - An Introduction to GraphQL Slides Chris C Williams Airbnb - Data Visualizations at Airbnb  Takeaways It‚Äôs always a great experience to attend a meetup. I love to meet people and talk about their projects. It serves me as the source of inspiration and sparks new ideas about how I could solve problems differently. It was great to see how Zendesk builds accessible component. I built something on a much smaller scale 18 months ago to enable our UI test automation framework to interact with our embedded web app. A different application for accessibility features in web apps.\nAlthough I don‚Äôt have an immediate use for GraphQL in my current project, I like the idea and concepts, since I remember from a previous project the issues GraphQL can solve. I think I‚Äôm going to use it in a side project that I was thinking about some time now.\nI love data visualization! I don‚Äôt use it as much as I‚Äôd like, but it‚Äôs great to see that reactjs components exist to quickly build stunning dashboards or add a helpful chart to (web) apps. I‚Äôm going to check it out on the weekend and see where I can use it for.\n Endless possibilities limited only by my imagination.\n Thanks üëè An enormous thank you goes out to Devon Lindsey for organizing the meetup and Zendesk for providing space, food and, resources.\n","ref":"/post/reactjs_meetup_zendesk/"},{"title":"Resize APFS Container in macOS 10.13 VMWare Image","date":"","description":"Resize APFS VoContainerlume in macOS 10.13 VMWare Image","body":"Resize VMWare Disk size VMWare provides an option to resize the Hard disk of a VM. The Settings dialog provides this option under Hard Disk. If the VM is not running and you don\u0026rsquo;t have a snapshot, the slider is enabled, and you can size the disk to your desired size.\nI wanted to increase the size of the hard disk from 50 GB to 100 GB. That\u0026rsquo;s a matter of seconds, and I was ready to go.\nI\u0026rsquo;ve launched the VM image and checked the hard disk size. To my surprise, the size was still 50 GB and not the promised 100 GB.\nWhat happened The request to change the hard disk size didn\u0026rsquo;t make it to macOS. I started to examine the disk with diskutil.\nlab-vm: user$ diskutil list /dev/disk0 (internal, physical): #: TYPE NAME SIZE IDENTIFIER 0: GUID_partition_scheme *107.4 GB disk0 1: EFI EFI 209.7 MB disk0s1 2: Apple_APFS Container disk1 50.2 GB disk0s2 /dev/disk1 (synthesized): #: TYPE NAME SIZE IDENTIFIER 0: APFS Container Scheme - +50.2 GB disk1 Physical Store disk0s2 1: APFS Volume macOS 10.13 23.2 GB disk1s1 2: APFS Volume Preboot 18.6 MB disk1s2 3: APFS Volume Recovery 509.8 MB disk1s3 4: APFS Volume VM 20.5 KB disk1s4 Well, the size was changed successfully. That\u0026rsquo;s good to see. But the reported size for the disk was still 50 GB. I noticed the Container disk1. This one had the reported size of 50 GB. It looks like; this has to be changed to make use of all the available space of that hard disk. After reading a little bit about APFS and how to deal with APFS, I learned that the hard disk is called a Volume. A Volume can have multiple containers.\nI found this command to change the size of the container to grow and use all the available space of the Volume (I had sweaty palms)\ndiskutil apfs resizeContainer /dev/disk1 0 Break down of the command, and its arguments,\n diskutil apfs =\u0026gt; tell diskutil that we are gonna modify something that has an APFS filesystem resizeContainer /dev/disk1 0 =\u0026gt; resize container /dev/disk1 and grow to the maximum available space (0)  Not bad! That worked smoother than expected. Now I have the full 100 GB available and can continue filling it up. :-)\nThanks for reading. I hope it\u0026rsquo;s helpful.\nFeel free to share and leave a comment. I\u0026rsquo;m happy to learn about your experience.\n","ref":"/post/til-resize-apfs-container-in-macos-10.13-vmware-image/"},{"title":"Effective Git - Worktrees","date":"","description":"Worktrees can save time switching between different feature branches","body":"You know this situation: you are working on new feature branch of your product. A bunch of files has been changed, nothing has settled yet and lots of uncommitted changes. This is how work in progress looks like. Everything could be alright, but then you are asked to check out that high priority issue that a customer reported.\nWhat I did in this situation\n stash my changes with git stash save and provide a meaningful message for when I have to unstash- my changes changes branches and pull from master build the product repro the issue create a new branch for the fix implement the fix and push to the newly created branch let somebody else verify the fix go back to my previous branch git stash pop my work in progress continue working on the feature  Introducing Worktrees I was reading git release notes, and I stumbled upon something I haven‚Äôt heard before in the git context: worktree. It‚Äôs not a new feature. It was introduced back in 2015, but I discovered it a couple of weeks ago. It reminded me of the time when I used Perforce, and I had to create a Workspace for everything I was working on (okay, it wasn‚Äôt that bad).\nThe help for git help worktree gives you a very short summary of some operations available for worktrees.\nNAME git-worktree - Manage multiple working trees SYNOPSIS git worktree add [-f] [--detach] [--checkout] [--lock] [-b \u0026lt;new-branch\u0026gt;] \u0026lt;path\u0026gt; [\u0026lt;branch\u0026gt;] git worktree list [--porcelain] git worktree lock [--reason \u0026lt;string\u0026gt;] \u0026lt;worktree\u0026gt; git worktree prune [-n] [-v] [--expire \u0026lt;expire\u0026gt;] git worktree unlock \u0026lt;worktree\u0026gt; Sounds interesting to me. Let‚Äôs check it out.\nIMHO worktrees have a couple of advantages over another git clone:\n less space wasted with another clone of the same repo easier to compare files between different worktrees work on multiple branches of the same repo without the hassle of messing everything up when switching branches (this happened a lot for me in the past)   BTW: the current project directory is a worktree too.\n There might be other good solutions to support that sort of workflows. Git is versatile and powerful. It has a lot to offer, and there are so many different ways to achieve the same result. Worktrees are a great addition, and they make good sense. Your mileage may vary.\nThanks for reading!\nFeel free to share, leave a comment or ignore it.\n","ref":"/post/effective-git-worktrees/"},{"title":"Efficient JavaScript Unit Testing with Jest and Snapshots","date":"","description":"Make your software testing life easier with Jest and Snapshots to test your javascript code","body":"Let\u0026rsquo;s start with a bold statement:\n We all love to write unit great tests for our code. More or less.\n‚Äî Unknown Programmer\n Writing unit tests for my code mostly follows this pattern\n Write a test and make it fail (red) Write the function to fix the test (implement function) Start over with step 1  For one of my projects, I was using jest. It\u0026rsquo;s fast now, and it has several features that I highly value. Most of them integrated code coverage and Snapshot testing.\nSnapshot testing? What\u0026rsquo;s that? When I first saw the part about Snapshot testing, I wasn\u0026rsquo;t interested. Okay, it was more that I thought, well, I don\u0026rsquo;t see a big advantage here over the traditional approach of testing my code. I\u0026rsquo;m calling functions and make sure that the result of those functions matches my expectations. That\u0026rsquo;s pretty simple with a function that returns a simple result Writing unit tests for my code mostly follows this pattern\n1function add(a, b) { 2 return a + b; 3}; 4 5test(\u0026#34;Verify that 1 + 3 equals 4\u0026#34;, () =\u0026gt; { 6 expect(add(1, 3)).toBe(4); 7});  This is simple and doesn‚Äôt require much work.\nHow about this?\n1function createTodoItem(subject, projects, contexts, due) { 2 return { 3 \u0026#34;subject\u0026#34;: subject, 4 \u0026#34;projects\u0026#34;: projects, 5 \u0026#34;contexts\u0026#34;: contexts, 6 \u0026#34;due\u0026#34;: due, 7 \u0026#34;completed\u0026#34;: false, 8 \u0026#34;archived\u0026#34;: false, 9 \u0026#34;isPriority\u0026#34;: false 10 } 11}; 12 13test(\u0026#34;Verify that new todo item has all required fields\u0026#34;, () =\u0026gt; { 14 const newTodoItem = createTodoItem(\u0026#34;New Task\u0026#34;, [\u0026#34;blog\u0026#34;], [\u0026#34;learn\u0026#34;, \u0026#34;programming\u0026#34;], \u0026#34;2017-04-17\u0026#34;); 15 const expectedTodoItem = {} 16 17 expect(newTodoItem).toEqual(expectedTodoItem); 18});  As expected, the output is telling me, that there is something missing. Yes, I didn‚Äôt write yet the expected object to compare the result with. I‚Äôm too lazy, and I always want to avoid writing it. What I‚Äôm doing instead, is to call the function, copy the result and create my expected result object with this data. But for now, I‚Äôm not going to do it. Let‚Äôs see, how Snapshot testing will help solve this task.\n1Verify that new todo item has all required fields 2 3 expect(received).toEqual(expected) 4 5 Expected value to equal: 6 {} 7 Received: 8 {\u0026#34;archived\u0026#34;: false, \u0026#34;completed\u0026#34;: false, \u0026#34;contexts\u0026#34;: [\u0026#34;learn\u0026#34;, \u0026#34;programming\u0026#34;], \u0026#34;due\u0026#34;: \u0026#34;2017-04-17\u0026#34;, \u0026#34;isPriority\u0026#34;: false, \u0026#34;projects\u0026#34;: [\u0026#34;blog\u0026#34;], \u0026#34;subject\u0026#34;: \u0026#34;New Task\u0026#34;} 9 10 Difference: 11 12 - Expected 13 + Received 14 15 -Object {} 16 +Object { 17 + \u0026#34;archived\u0026#34;: false, 18 + \u0026#34;completed\u0026#34;: false, 19 + \u0026#34;contexts\u0026#34;: Array [ 20 + \u0026#34;learn\u0026#34;, 21 + \u0026#34;programming\u0026#34;, 22 + ], 23 + \u0026#34;due\u0026#34;: \u0026#34;2017-04-17\u0026#34;, 24 + \u0026#34;isPriority\u0026#34;: false, 25 + \u0026#34;projects\u0026#34;: Array [ 26 + \u0026#34;blog\u0026#34;, 27 + ], 28 + \u0026#34;subject\u0026#34;: \u0026#34;New Task\u0026#34;, 29 +} 30 31 at Object.\u0026lt;anonymous\u0026gt;.test (__tests__/newTask-test.js:7:25) 32 at process._tickCallback (internal/process/next_tick.js:109:7) 33 34 PASS __tests__/add-test.js 35 36Test Suites: 1 failed, 1 passed, 2 total 37Tests: 1 failed, 1 passed, 2 total 38Snapshots: 0 total 39Time: 1.042s 40Ran all test suites.  Yeah, I was lazy and didn‚Äôt populate expectedTodoItem with all the fields I was expecting. This is the point, where Snapshot testing comes into play. It helps me lazy programmer to avoid writing unnecessary code only to verify my assumptions about the outcome of that function.\n1function createTodoItem(subject, projects, contexts, due) { 2 return { 3 \u0026#34;subject\u0026#34;: subject, 4 \u0026#34;projects\u0026#34;: projects, 5 \u0026#34;contexts\u0026#34;: contexts, 6 \u0026#34;due\u0026#34;: due, 7 \u0026#34;completed\u0026#34;: false, 8 \u0026#34;archived\u0026#34;: false, 9 \u0026#34;isPriority\u0026#34;: false 10 } 11}; 12 13test(\u0026#34;Verify that new todo item has all required fields\u0026#34;, () =\u0026gt; { 14 const newTodoItem = createTodoItem(\u0026#34;New Task\u0026#34;, [\u0026#34;blog\u0026#34;], [\u0026#34;learn\u0026#34;, \u0026#34;programming\u0026#34;], \u0026#34;2017-04-17\u0026#34;); 15 16 expect(newTodoItem).toMatchSnapshot(); 17});  And here the result.\n1PASS __tests__/newTask-test.js 2PASS __tests__/add-test.js 3 4Test Suites: 2 passed, 2 total 5Tests: 2 passed, 2 total 6Snapshots: 1 passed, 1 total 7Time: 0.816s, estimated 1s 8Ran all test suites.  Three notable things  I still didn‚Äôt provide a full-fledged object that matches my expectation toMatchSnapshot() was the only code change in the test The number of Snapshots in the status output of Jest is now 1!  What happened? Jest was taking a Snapshot for that test and was happy with the result. Under the hood, Jest created a __snapshots__ directory in my __tests__ directory and saved the output of the test result. The file is named after the file containing the test. In this case, it‚Äôs newTask-test.js.snap. Here are the contents of that Snapshot file.\n1// Jest Snapshot v1, https://goo.gl/fbAQLP 2 3exports[`Verify that new todo item has all required fields 1`] = ` 4Object { 5\u0026#34;archived\u0026#34;: false, 6\u0026#34;completed\u0026#34;: false, 7\u0026#34;contexts\u0026#34;: Array [ 8\u0026#34;learn\u0026#34;, 9\u0026#34;programming\u0026#34;, 10], 11\u0026#34;due\u0026#34;: \u0026#34;2017-04-17\u0026#34;, 12\u0026#34;isPriority\u0026#34;: false, 13\u0026#34;projects\u0026#34;: Array [ 14\u0026#34;blog\u0026#34;, 15], 16\u0026#34;subject\u0026#34;: \u0026#34;New Task\u0026#34;, 17} 18`;  The key of the exports object is the name of the test itself. The value of it is the result from createTodoItem(\u0026quot;New Task\u0026quot;, [\u0026quot;blog\u0026quot;], [\u0026quot;learn\u0026quot;, \u0026quot;programming\u0026quot;], \u0026quot;2017-04-17\u0026quot;). That is great. I didn‚Äôt have to type a line of code for the expected result of this function. By doing a quick visual inspection of the output, I can confirm that this is the expected output.\nNow it gets interesting. I‚Äôm going to change the return object of the function. The result object will have a new key completedDate and the completed flag will be removed. Let‚Äôs see how Jest handles the situation without making any change to the existing, and currently passing, test.\n1 FAIL __tests__/newTask-test.js 2 ‚óè Verify that new todo item has all required fields 3 4 expect(value).toMatchSnapshot() 5 6 Received value does not match stored snapshot 1. 7 8 - Snapshot 9 + Received 10 11 @@ -1,8 +1,8 @@ 12 Object { 13 \u0026#34;archived\u0026#34;: false, 14 - \u0026#34;completed\u0026#34;: false, 15 + \u0026#34;completedDate\u0026#34;: \u0026#34;\u0026#34;, 16 \u0026#34;contexts\u0026#34;: Array [ 17 \u0026#34;learn\u0026#34;, 18 \u0026#34;programming\u0026#34;, 19 ], 20 \u0026#34;due\u0026#34;: \u0026#34;2017-04-17\u0026#34;, 21 22 at Object.\u0026lt;anonymous\u0026gt;.test (__tests__/newTask-test.js:8:25) 23 at process._tickCallback (internal/process/next_tick.js:109:7) 24 25 PASS __tests__/add-test.js 26 27Snapshot Summary 28 ‚Ä∫ 1 snapshot test failed in 1 test suite. Inspect your code changes or run with `npm test -- -u` to update them. 29 30Test Suites: 1 failed, 1 passed, 2 total 31Tests: 1 failed, 1 passed, 2 total 32Snapshots: 1 failed, 1 total 33Time: 1.113s 34Ran all test suites.  The output of the test run informs me that the Received value does not match stored snapshot 1. That is correct, and it was expected. But more importantly, Jest tells me to inspect my code changes or run the tests again with a specific flag to update the snapshot. Since it was an intentional change, I‚Äôm going to run the test again with npm test -- -u to update the Snapshot.\n1\u0026gt; jest \u0026#34;-u\u0026#34; 2 3 PASS __tests__/newTask-test.js 4 PASS __tests__/add-test.js 5 6Snapshot Summary 7 ‚Ä∫ 1 snapshot updated in 1 test suite. 8 9Test Suites: 2 passed, 2 total 10Tests: 2 passed, 2 total 11Snapshots: 1 updated, 1 total 12Time: 1.115s 13Ran all test suites.  The Snapshot got updated and reflects the current implementation of my function. Well done! No code is written to create the expected result object. This is where Snapshot testing is awesome.\nSummary I hope that this example helped to understand the Snapshot testing capability of Jest. IMHO, this approach is excellent for two reasons:\n I don\u0026rsquo;t have to write code to compare complex result objects Less test code to write, easier to read, more time to work on features  Snapshot testing might not be necessary/wanted for all kind of tests. You might choose the traditional way for simpler functions. To verify complex result objects, this is an efficient way for testing. Having to write less code is always a great way to improve efficiency.\nDon\u0026rsquo;t hesitate to contact me, if you have questions or suggestions. You can leave a comment below or find me on the social networks mentioned at the top of this post.\nThank you very much for reading!\n","ref":"/post/efficient-unit-testing-with-jest-and-snapshots/"},{"title":"Weekly Wallpaper Week 09/2017","date":"","description":"My Wallpaper for the 9th week of 2017","body":"Wallpaper Week 09/2017 Howdy New York February 2005. I arrived in New York for a weekend stop over on the way to San Francisco. I wanted to visit the The Gates in Central Park.\nI was hoping for some snow during the night and some sun for Saturday morning. I wanted to capture the glowing orange fabric surrounded by the bright white environment. When I woke up Saturday morning, I was surprised to see that both wishes had come true. There was sun and snow! Awesome.\nAbout the Image The image was taken with a Canon EOS 10D and the Tamron AF 28-75mm f/2.8 SP XR Di LD Aspherical (28mm, f/6.7, 1‚ÅÑ250, ISO 100).\nI used Adobe Lightroom 6.8 to sharpen, crop and increase the contrast of the image. I reduced the saturation for all colors except orange.\nOrange Gates.\nThanks for reading!\nFeel free to share, leave a comment or just enjoy looking at it.\n","ref":"/wallpaper/2017/week-09/_index09/"},{"title":"Weekly Wallpaper Week 08/2017","date":"","description":"My Wallpaper for the 8th week of 2017","body":"Wallpaper Week 08/2017 Howdy I spent last Weekend in Yosemite, CA. It was a birthday present that my wife gave me. No children, away from home and time to attend a photography class in Yosemite. The class was organized from the Ansel Adams Gallery.\nThe class was 4 hours long and I took a lot of shots during the class. It was a lot of experimentation with the camera. How to deal with over-exposure, composition, color, white balancing, experiments with aperture priority, etc.\nThe photo was taken outside the national park. On the way to Yosemite Valley, I stopped on this little bridge. I went down to the river and tried several things with the camera. I enjoyed the white noise of the rushing river. Then I discovered the stone pyramid that somebody left behind. I like those pyramids. They look fragile and solid at the same time. And it seems, that the recent storms didn\u0026rsquo;t do any harm to it.\nAbout the Image The image was taken with a Sony Alpha A7RII and the FE 24-70mm F4 ZA O (25mm, f/4.0, 1‚ÅÑ60, ISO 4000).\nI used Adobe Lightroom 6.8 to sharpen, crop and increase the contrast of the image.\nStatic Flow.\nThanks for reading!\nFeel free to share, leave a comment or just enjoy looking at it.\n","ref":"/wallpaper/2017/week-08/_index08/"},{"title":"Weekly Wallpaper Week 07/2017","date":"","description":"My Wallpaper for the 7th week of 2017","body":"Wallpaper Week 07/2017 Howdy I spent last Tuesday in San Jose, CA at the bi-annual Adobe developer conference that took place in the San Jose Convention Center. The evening of the second day usually ends with the TechFair. Teams are showing off what they are working on. That\u0026rsquo;s the most interesting part of the whole conference. You get some ideas about what is going on in the company and where we are heading. The whole decoration for the venue was using glow sticks all over the place. People wore them, some large glow sticks were hanging from the ceiling.\nAbout the Image The image was taken with a Sony Alpha A7RII and the FE 24-70mm F4 ZA O (25mm, f/4.0, 1‚ÅÑ60, ISO 4000).\nI used Adobe Lightroom 6.8 to sharpen the image and reduce some luminance noise.\nGlow in the Dark.\nThanks for reading!\nFeel free to share, leave a comment or just enjoy looking at it.\n","ref":"/wallpaper/2017/week-07/_index07/"},{"title":"Weekly Wallpaper Week 06/2017","date":"","description":"My Wallpaper for the 6th week of 2017","body":"Wallpaper Week 06/2017 Happy Monday!\nAbout the Image Last Sunday I was spending some time walking around the football field at our middle school. The weather wasn\u0026rsquo;t that great. Grey and cloudy skies and lots of gusty winds. Then my little daughter showed up with some daisies she has picked from the field. It looked so fragile, how she was holding the tiny flowers in her little hands. Squeezed between her little fingers. Her purple jacket and the blue ball made were a great colorful subject that day.\nThe image was taken with a Sony Alpha A7II and the 28-70 mm Lens (44mm, f/4.5, 1‚ÅÑ160, ISO 125).\nI used Lightroom 6.8 to crop the image. I sharpened the image a little bit and reduced some luminance noise.\nDaisy in little hands.\nThanks for reading!\nFeel free to share, leave a comment or just enjoy looking at it.\n","ref":"/wallpaper/2017/week-06/_index06/"},{"title":"Weekly Wallpaper Week 05/2017","date":"","description":"My Wallpaper for the 5th week of 2017","body":"Happy Monday!\nAbout the Image As you can see: I love Santa Cruz!. This photo was taken on 02/14/2016. I spent the long weekend with my family in Santa Cruz. We stayed close to that beautiful beach and spent the afternoon in the sun.\nThe image was taken with a Sony Alpha A7II and the 28-70 mm Lens (53mm, f/9, 1‚ÅÑ250, ISO 100).\nI used Lightroom to crop the image a little bit. I made some adjustements on the white balance and bumped the sharpness slightly up.\nSanta Cruz Beach\nThanks for reading!\nFeel free to share, leave a comment or just enjoy looking at it.\n","ref":"/wallpaper/2017/week-05/_index05/"},{"title":"Weekly Wallpaper Week 04/2017","date":"","description":"My Wallpaper for the 4th week of 2017","body":"Wallpaper Week 04/2017 About the Image Happy Monday!\nThis week, I have again a photo from Santa Cruz, CA. I‚Äôve taken this photo on 01/15/2017, during my Sunday trip to the beach. The image was taken with a Sony Alpha A7II and the 28-70 mm Lens (70mm, f/9, 1‚ÅÑ200, ISO 100).\nThe photo was slightly rotated to have straight vertical lines. I used the Lightroom Blue Hi-Contrast Filter for B/W conversion.\nSanta Cruz Wharf\nThanks for reading!\n","ref":"/wallpaper/2017/week-04/_index04/"},{"title":"My Wallpaper Photo of the Week","date":"","description":"My Wallpaper of the Week","body":"My Wallpaper Photo of the Week Every Monday, I\u0026rsquo;ll post the photo, that will be my Desktop background for one week. I\u0026rsquo;ll give a description of the subject, where it was taken and what the camera settings were (if I remember them). All photos will be taken by myself. I\u0026rsquo;ll release them in the highest availble quality. If you like a photo, you can download it for your personal use. Each photo contains a watermark with my name and year.\nPlease read below if you want to license a photo or use it for something different altogether.\nMotivation Why am I releasing some of my pictures for free? The reason is, that I took so many photos in the past couple of years, that I think it\u0026rsquo;s really a shame to burry them somewhere on my computer. I don\u0026rsquo;t look at them that often, but every time I do, I\u0026rsquo;m surprised and happy for what I found.\nSome people told me, that they like my photos. I always feel humbled by that. I want to enjoy some of the photos myself by using them as wallpaper for my desktop. Perhaps you find a photo that you like too.\nSome final Notes:\n This is no competition If you have any questions about a photo, please leave a comment in the section below Share your thoughts in the comment section below  Copyright and Licensing Please contact me if you want to use a photo in a commercial context (you will make money with it). Using it as wallpaper on your phone, tablet, notebook, desktop machine is alright. You are not allowed to remove the watermark.\n","ref":"/post/my-wallpaper-photo-of-the-week/"},{"title":"Weekly Wallpaper Week 03","date":"","description":"My Wallpaper for the 3rd week of 2017","body":"Wallpaper Week 03/2017 About the Image The image was taken on my iPhone 7 Plus with Microsoft Pix. Finishing touches with Adobe Lightroom 6.8. Sunset in Santa Cruz last Sunday (01/15/2017)\nThanks for reading! üì∑\n","ref":"/wallpaper/2017/week-03/_index03/"},{"title":"Get Up And Start Walking","date":"","description":"","body":" \u0026#34;\u0026#34; If you want something you never had, then do something you never did. \u0026#34;\u0026#34;  ‚Äî Nossrat Peseschkian   When I heard the above quote for the first time, it was eye opening to me. Why? It expresses very clearly to me, that you need to get active, if you want to reach a goal in your life. No matter what it is. Get a promotion, earn more money, hike the Pacific Crest Trail. You get the idea.\n I‚Äôm a software engineer working for a big company. I don‚Äôt like to stand still and do the same things on a daily basis. I like challenges and the unknown. Exploring new tools, frameworks and languages is part of my nature. But not everybody has the same degree of freedom at work.\n Being a programmer, engineer, software developer, front/back-end developer provides enough challenges on a daily basis. What if you want more? How do you get to the next level? Do you want to be Dev Lead? You want more responsibility? Or you just want to earn more money?\n   What is your plan to get there? In recent job interviews, I asked candidates if they tried tool/framework/language/skill that is useful for the job.\n In a lot of cases, I heard one of the following answers - nobody asked me to look at it - I was busy doing my day to day job - my Manager didn‚Äôt give me permission to do so\n I totally understand that we are all living busy lives. I have a demanding full time job, a family and some friends. All of them require time and time is a scarce resource. Once it‚Äôs gone, you won‚Äôt get it back. So act wisely! You wanted to reach goal A/B/C, right? The I call the answers lame excuses.\n Don‚Äôt tell me that you didn‚Äôt have the permission, time, energy to learn something valuable or new. This is your life, your career and these are your goals. You don‚Äôt need to ask for permission to learn.\n   Be Bold. Do it. Do it every day. Set aside some time during the day. Create an event in your calendar and plan for it. Tell somebody, show the results. That is the only way that works to get it going. Move out of your comfort zone and learn that awesome tool/framework/language/skill.\n A journey starts with a first step. Go out there and start walking. Or as Lao Tse said\n A journey of a thousand miles begins with a single step.   This is a great closing for the upcoming week. Think about what you want to reach. How can you get there?. It doesn‚Äôt have to be the perfect plan. But hey: you want to reach that goal. So, make a plan and act according to your plan.\n Talk to you next week.\n   ","ref":"/post/get-up-and-start-walking/"},{"title":"TIL - SIGINFO is awesome","date":"","description":"","body":"Today I learnt something really awesome. If you use a Unix based operating system, then you will be able to send any process a signal. This might be either Ctrl+C or SIGINT to interrupt that process. Or you can send SIGINFO to report the progress of it‚Äôs operation. Why this is awesome? Did you ever copy a huge amount of data and cp didn‚Äôt tell you how much has data has been copied so far? SIGINT to the rescue.\n irichter@irichter-MacBookPro:~/Documents/Virtual Machines ¬ª cp -a dev-setup.vmwarevm dev-setup-2.vmwarevm load: 2.02 cmd: cp 49102 uninterruptible 0.05u 2.28s dev-setup.vmwarevm/dev-setup-61da15a0.vmem -\u0026gt; dev-setup-2.vmwarevm/dev-setup-61da15a0.vmem 32% load: 2.02 cmd: cp 49102 uninterruptible 0.06u 4.11s dev-setup.vmwarevm/dev-setup-61da15a0.vmem -\u0026gt; dev-setup-2.vmwarevm/dev-setup-61da15a0.vmem 74%   I send Ctrl+T two times to the cp process. In one case 32% of the data has been copied. In the other case 74%.\n This will help especially with programs that don‚Äôt have an option to report progress.\n ","ref":"/post/til-siginfo-is-awesome/"},{"title":"Don't say it. Do it!","date":"","description":"","body":"  Don‚Äôt talk too much about the things you want to do.\n  Don‚Äôt overthink everything.\n  Don‚Äôt make it more complicated than it has to be.\n  Don‚Äôt stop learning.\n  Don‚Äôt stop trying.\n  Try harder.\n  Try smarter.\n  Don‚Äôt say ‚Äúit‚Äôs impossible‚Äù.\n  Move faster.\n   Do it!\n ","ref":"/post/dont-say-it-do-it/"},{"title":"TIL - Reactjs optimization that cost me some time","date":"","description":"","body":"I was building a Reactjs component, that should toggle between two child components.\n \u0026lt;Toggle\u0026gt; \u0026lt;Comp1\u0026gt; \u0026lt;Comp2\u0026gt; \u0026lt;/Toggle\u0026gt;   The render method of Toggle looked like this\n render() { const content = React.Children.count(this.props.children) \u0026gt; 0 ? this.props.children[0] : this.props.children[1]; return ( ${content} ); }   Unfortunately, this didn‚Äôt work (index out of bounds), when I passed only one component instead of two. This doesn‚Äôt make sense since the Toggle is supposed to toggle between two components. So, you could argue, that I broke the contract by not passing two child components to Toggle. That is all true.\n What I want to show instead, is the fact that if you pass only one child component, then this.props.children is not an array anymore. this.props.children is the one component. Which explains the index out of bounds error.\n Some information about dealing with this.props.children is available here.\n Thanks for reading!\n ","ref":"/post/reactjs-optimizations/"},{"title":"TIL - where to put ant-contrib","date":"","description":"","body":"I was testing an ant based build script change today. And I thought ant was already retired.\n Running the script led to a lot of warnings about a missing library. I asked the person, if there are any dependencies for ant-contrib. His response was \u0026#34;yes, you need to install ant-contrib\u0026#34;.\n First of all, I didn‚Äôt have ant installed. But that was easy with\n irichter@irichter-MacBookPro:~ brew install ant   Unfortunately, ant-contrib wasn‚Äôt available via homebrew, so I had to download it and place it‚Ä¶‚Äã where? Ah, in the lib folder of your ant installation. Okay, that might one solution. I remembered, that years ago I was using it in a different way. There was another location where ant was looking for additional jars.\n This worked for me  create or locate the ~/.ant/lib directory\n  copy all additional jars in this directory\n   From now on, ant will be able to find ant-contrib and I don‚Äôt have to mess around with the ant installation directory. Clean, nice and simple solution.\n   Note  I don‚Äôt know, if this will work on Windows in the same way.     Thanks for reading!\n   ","ref":"/post/til-where-to-put-ant-contrib/"},{"title":"Welcome to my new blog presence","date":"","description":"","body":"After a long time, I‚Äôm finally moving my blog to this new github hosted location. Cleaner setup, easier to maintain and independent from any content management system.\n This will be home to all new posts in the future. There will be tweaks to the setup and layout in the next couple of days. It‚Äôs not perfect yet, but I wanted to get it going. The blog will be available under this domain.\n I hope you will find something useful here.\n Hope to see you soon. Stay tuned.\n   Ingo\n   ","ref":"/post/welcome-to-my-new-blog/"}]